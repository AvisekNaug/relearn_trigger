{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T20:46:13.301011Z",
     "start_time": "2020-07-31T20:46:12.784000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# import modules\n",
    "from alumni_scripts import data_process as dp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T18:06:59.581490Z",
     "start_time": "2020-06-26T18:06:59.131895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run a single update of the data pull\n",
    "with open('../auths.json', 'r') as fp:\n",
    "    api_args = json.load(fp)\n",
    "\n",
    "time_args = {\n",
    "    'start_year': 2019,'start_month': 4,'start_day': 1,'start_hour': 20,'start_minute': 0,'start_second': 0,\n",
    "    'end_year':   2019,'end_month'  : 4,'end_day'  : 2,'end_hour'  : 2,'end_minute'  :  0,'end_second'  : 0,\n",
    "    'trend_id': '2681',\n",
    "    'save_path':'../data/raw_data/alumni_data.csv'\n",
    "}\n",
    "api_args.update(time_args)\n",
    "\n",
    "dp.pull_offline_data(**api_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# download data in a loop\n",
    "time_args = [\n",
    "    {\n",
    "    'start_year': 2018,'start_month': 7,'start_day': 1,'start_hour': 0,'start_minute': 0,'start_second': 0,\n",
    "    'end_year': 2018,'end_month': 12,'end_day': 31,'end_hour': 23,'end_minute': 59,'end_second': 59,\n",
    "    'trend_id': '2681',\n",
    "    'save_path':'../data/raw_data/alumni_data_jul2dec2018.csv'\n",
    "    },\n",
    "    {\n",
    "    'start_year': 2019,'start_month': 1,'start_day': 1,'start_hour': 0,'start_minute': 0,'start_second': 0,\n",
    "    'end_year': 2019,'end_month': 6,'end_day': 30,'end_hour': 23,'end_minute': 59,'end_second': 59,\n",
    "    'trend_id': '2681',\n",
    "    'save_path':'../data/raw_data/alumni_data_jan2jun2019.csv'  \n",
    "    },\n",
    "    {\n",
    "    'start_year': 2019,'start_month': 7,'start_day': 1,'start_hour': 0,'start_minute': 0,'start_second': 0,\n",
    "    'end_year': 2019,'end_month': 12,'end_day': 31,'end_hour': 23,'end_minute': 59,'end_second': 59,\n",
    "    'trend_id': '2681',\n",
    "    'save_path':'../data/raw_data/alumni_data_jul2dec2019.csv'  \n",
    "    },\n",
    "    {\n",
    "    'start_year': 2020,'start_month': 1,'start_day': 1,'start_hour': 0,'start_minute': 0,'start_second': 0,\n",
    "    'end_year': 2020,'end_month': 6,'end_day': 15,'end_hour': 23,'end_minute': 59,'end_second': 59,\n",
    "    'trend_id': '2681',\n",
    "    'save_path':'../data/raw_data/alumni_data_jan2jun2020.csv'  \n",
    "    }\n",
    "]\n",
    "for i in time_args:\n",
    "    with open('../auths.json', 'r') as fp:\n",
    "        api_args = json.load(fp)\n",
    "    api_args.update(i)\n",
    "    dp.pull_offline_data(**api_args)\n",
    "    print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Deployment testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T18:48:38.178110Z",
     "start_time": "2020-06-26T18:48:34.514080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# testing the deploy control thread\n",
    "\"\"\" change path in the deploy control thread to save the file to appropriate location\"\"\"\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    from alumni_scripts import deploy_control as dc\n",
    "\n",
    "with open('../auths.json', 'r') as fp:\n",
    "    api_args = json.load(fp)\n",
    "with open('../alumni_scripts/meta_data.json', 'r') as fp:\n",
    "    meta_data_ = json.load(fp)\n",
    "obs_space_vars = ['oat', 'oah', 'wbt', 'avg_stpt', 'sat']\n",
    "\n",
    "df = dc.get_real_obs(api_args, meta_data_, obs_space_vars)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Offline Batch Time Series Data Base for Alumni Hall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T16:59:25.779805Z",
     "start_time": "2020-08-11T16:59:24.798309Z"
    }
   },
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# import modules\n",
    "from alumni_scripts import data_process as dp\n",
    "from alumni_scripts import alumni_data_utils as a_utils\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from influxdb import DataFrameClient\n",
    "from collections import OrderedDict\n",
    "from CoolProp.HumidAirProp import HAPropsSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate the data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:29:51.933760Z",
     "start_time": "2020-06-29T15:29:51.718809Z"
    }
   },
   "outputs": [],
   "source": [
    "# collate batch of data\n",
    "file_names = ['jul2dec2018', 'jan2jun2019', 'jul2dec2019', 'jan2jun2020']\n",
    "dflist = []\n",
    "for fname in file_names:\n",
    "    df_ = pd.read_csv('../data/raw_data/alumni_data_{}.csv'.format(fname))\n",
    "    df_['time'] = pd.to_datetime(df_['time'])\n",
    "    df_.set_index(keys='time',inplace=True, drop = True)\n",
    "    dflist.append(df_)\n",
    "df = a_utils.mergerows(dflist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Wet Bulb Temperature and add it to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:30:03.167935Z",
     "start_time": "2020-06-29T15:30:03.158776Z"
    }
   },
   "outputs": [],
   "source": [
    "rh = df['WeatherDataProfile humidity']/100\n",
    "rh = rh.to_numpy()\n",
    "t_db = 5*(df['AHU_1 outdoorAirTemp']-32)/9 + 273.15\n",
    "t_db = t_db.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:16:22.674946Z",
     "start_time": "2020-06-21T17:00:06.936402Z"
    }
   },
   "outputs": [],
   "source": [
    "T = HAPropsSI('T_wb','R',rh,'T',t_db,'P',101325)\n",
    "t_f = 9*(T-273.15)/5 + 32\n",
    "df['wbt'] = t_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:19:07.937617Z",
     "start_time": "2020-06-21T17:19:07.687429Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Create column_aliases\n",
    "d1 = {'column_names': list(df.columns)}\n",
    "column_aliases = [\n",
    "    'pchwst', 'vrf50', 'oat', 'sat', 'sat_stpt', 'oah', 'vrf67', 'pchw_flow',\n",
    "    'hwe', 'vrf1', 'vrf30', 'vrf34', 'vrf74', 'cwe', 'hws_st_stpt', 'vrf60',\n",
    "    'vrf63', 'hws_st', 'hws_vlv1', 'vrf77', 'vrf64', 'vrf10', 'ee', 'hws_rt',\n",
    "    'vrf100', 'vrf40', 'hws_flow', 'vrf108', 'vrf20', 'wbt'\n",
    "]\n",
    "\n",
    "d1['column_agg_type'] = {\n",
    "    \"pchwst\": \"mean\",\"vrf50\": \"mean\",\"oat\": \"mean\",\"sat\": \"mean\",\"sat_stpt\": \"mean\",\"oah\": \"mean\",\n",
    "    \"vrf67\": \"mean\",\"pchw_flow\": \"sum\",\"hwe\": \"sum\",\"vrf1\": \"mean\",\"vrf30\": \"mean\",\"vrf34\": \"mean\",\n",
    "    \"vrf74\": \"mean\",\"cwe\": \"sum\",\"hws_st_stpt\": \"mean\",\"vrf60\": \"mean\",\"vrf63\": \"mean\",\"hws_st\": \"mean\",\n",
    "    \"hws_vlv1\": \"sum\",\"vrf77\": \"mean\", \"vrf64\": \"mean\",\"vrf10\": \"mean\",\"ee\": \"sum\",\"hws_rt\": \"mean\",\n",
    "    \"vrf100\": \"mean\",\"vrf40\": \"mean\",\"hws_flow\": \"sum\",\"vrf108\": \"mean\",\"vrf20\": \"mean\", 'wbt' : \"mean\"\n",
    "}\n",
    "\n",
    "# Create column alias\n",
    "d2 = OrderedDict()\n",
    "for i, j in zip(df.columns, column_aliases):\n",
    "    d2.update({j: i})\n",
    "d1['column_aliases'] = d2\n",
    "\n",
    "df.columns = column_aliases\n",
    "\n",
    "# Create column stats\n",
    "stats = {}\n",
    "d3 = OrderedDict(df.describe())\n",
    "for key, alias in zip(d3.keys(), column_aliases):\n",
    "    stats[alias] = dict(d3[key])\n",
    "d1['column_stats'] = stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create half hour stats for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:19:11.453611Z",
     "start_time": "2020-06-21T17:19:11.167137Z"
    }
   },
   "outputs": [],
   "source": [
    "# aggregate data\n",
    "rolling_sum_target, rolling_mean_target = [], []\n",
    "for key, value in d1['column_agg_type'].items():\n",
    "    if value == 'sum': rolling_sum_target.append(key)\n",
    "    else: rolling_mean_target.append(key)\n",
    "\n",
    "df_agg = df.copy()\n",
    "        \n",
    "df_agg[rolling_sum_target] =  a_utils.window_sum(df_agg, window_size=6, column_names=rolling_sum_target)\n",
    "df_agg[rolling_mean_target] =  a_utils.window_mean(df_agg, window_size=6, column_names=rolling_mean_target)\n",
    "df_agg = a_utils.dropNaNrows(df_agg)\n",
    "# sample at half hour\n",
    "df_agg = a_utils.sample_timeseries_df(df_agg, period=6)\n",
    "\n",
    "# Create column stats for half hour data\n",
    "stats_halfhour = {}\n",
    "d4 = OrderedDict(df_agg.describe())\n",
    "for key, alias in zip(d4.keys(),column_aliases):\n",
    "    stats_halfhour[alias] = dict(d4[key])\n",
    "d1['column_stats_half_hour'] = stats_halfhour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:19:13.689909Z",
     "start_time": "2020-06-21T17:19:13.680430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create meta data json file\n",
    "with open('../alumni_scripts/meta_data.json', 'w') as fp:\n",
    "    json.dump(d1, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:19:29.004848Z",
     "start_time": "2020-06-21T17:19:28.836280Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned = dp.offline_batch_data_clean(meta_data_path='../alumni_scripts/meta_data.json', df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:19:37.939990Z",
     "start_time": "2020-06-21T17:19:37.935222Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned.columns = column_aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push data to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T17:20:39.849700Z",
     "start_time": "2020-06-21T17:20:29.594431Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before the next steps launch influxd client at a cli\n",
    "sudo influxd\n",
    "\"\"\"\n",
    "# launch python client for influxdb\n",
    "client = DataFrameClient(host='localhost', port=8086)\n",
    "# create a database inc case it's not there\n",
    "client.create_database('bdx_batch_db')\n",
    "# get list of database\n",
    "client.get_list_database()\n",
    "# switch to the databaase you want\n",
    "client.switch_database('bdx_batch_db')\n",
    "# write \"dataframe\" as \"measurements\"\n",
    "client.write_points(dataframe=df_cleaned,\n",
    "                    measurement='alumni_data_v2',\n",
    "                    tags={\n",
    "                        'data_cleaned': 'True',\n",
    "                        'aggregated': False,\n",
    "                        'time-interval': '5 minutes'\n",
    "                    },\n",
    "                    protocol='line',\n",
    "                    batch_size=5000)\n",
    "# see measurement added to curent db\n",
    "client.get_list_measurements()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:00:15.121878Z",
     "start_time": "2020-08-11T17:00:15.039498Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before the next steps launch influxd client at a cli\n",
    "sudo influxd\n",
    "\"\"\"\n",
    "# launch python client for influxdb\n",
    "client = DataFrameClient(host='localhost', port=8086)\n",
    "# switch to the databaase you want\n",
    "client.switch_database('bdx_batch_db')\n",
    "results_obj = client.query(\n",
    "    \"select * from alumni_data_v2 \\\n",
    "    where time >= '2019-11-19 00:00:00' - 40m \\\n",
    "    and time <= '2019-11-19 00:00:00'\", dropna=False\n",
    ")\n",
    "#df2 = results_obj['alumni_data_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_obj.keys()\n",
    "df2 = results_obj['alumni_data_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                           cwe   ee  hwe  hws_flow hws_rt hws_st hws_st_stpt  \\\n2019-11-18 23:20:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:25:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:30:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:35:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:40:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:45:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:50:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-18 23:55:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n2019-11-19 00:00:00+00:00  0.0  0.0  0.0       0.0   None   None        None   \n\n                           hws_vlv1        oah   oat  ...  vrf34  vrf40 vrf50  \\\n2019-11-18 23:20:00+00:00       0.0  42.261593  None  ...   None   None  None   \n2019-11-18 23:25:00+00:00       0.0  42.261593  None  ...   None   None  None   \n2019-11-18 23:30:00+00:00       0.0  42.261593  None  ...   None   None  None   \n2019-11-18 23:35:00+00:00       0.0  42.405796  None  ...   None   None  None   \n2019-11-18 23:40:00+00:00       0.0  42.405796  None  ...   None   None  None   \n2019-11-18 23:45:00+00:00       0.0  42.411228  None  ...   None   None  None   \n2019-11-18 23:50:00+00:00       0.0  42.411228  None  ...   None   None  None   \n2019-11-18 23:55:00+00:00       0.0  42.411228  None  ...   None   None  None   \n2019-11-19 00:00:00+00:00       0.0  42.411228  None  ...   None   None  None   \n\n                          vrf60 vrf63 vrf64 vrf67 vrf74 vrf77   wbt  \n2019-11-18 23:20:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:25:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:30:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:35:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:40:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:45:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:50:00+00:00  None  None  None  None  None  None  None  \n2019-11-18 23:55:00+00:00  None  None  None  None  None  None  None  \n2019-11-19 00:00:00+00:00  None  None  None  None  None  None  None  \n\n[9 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cwe</th>\n      <th>ee</th>\n      <th>hwe</th>\n      <th>hws_flow</th>\n      <th>hws_rt</th>\n      <th>hws_st</th>\n      <th>hws_st_stpt</th>\n      <th>hws_vlv1</th>\n      <th>oah</th>\n      <th>oat</th>\n      <th>...</th>\n      <th>vrf34</th>\n      <th>vrf40</th>\n      <th>vrf50</th>\n      <th>vrf60</th>\n      <th>vrf63</th>\n      <th>vrf64</th>\n      <th>vrf67</th>\n      <th>vrf74</th>\n      <th>vrf77</th>\n      <th>wbt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-11-18 23:20:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.261593</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:25:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.261593</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:30:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.261593</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:35:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.405796</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:40:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.405796</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:45:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.411228</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:50:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.411228</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-18 23:55:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.411228</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2019-11-19 00:00:00+00:00</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>42.411228</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows × 30 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "df2.drop(columns = ['data_cleaned', 'aggregated', 'time-interval'], inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "'sat_stpt' in df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "(df2.empty) | (df2.isnull().any().any()) | (df2.shape[0]<6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['cwe', 'ee', 'hwe', 'hws_flow', 'hws_rt', 'hws_st', 'hws_st_stpt',\n       'hws_vlv1', 'oah', 'oat', 'pchw_flow', 'pchwst', 'sat', 'sat_stpt',\n       'vrf1', 'vrf10', 'vrf100', 'vrf108', 'vrf20', 'vrf30', 'vrf34', 'vrf40',\n       'vrf50', 'vrf60', 'vrf63', 'vrf64', 'vrf67', 'vrf74', 'vrf77', 'wbt'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['cwe', 'ee', 'hwe', 'hws_flow', 'hws_rt', 'hws_st', 'hws_st_stpt',\n       'hws_vlv1', 'oah', 'oat', 'pchw_flow', 'pchwst', 'sat', 'sat_stpt',\n       'vrf1', 'vrf100', 'vrf108', 'vrf20', 'vrf30', 'vrf34', 'vrf40', 'vrf50',\n       'vrf60', 'vrf63', 'vrf64', 'vrf67', 'vrf74', 'vrf77', 'wbt'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:01:11.132132Z",
     "start_time": "2020-08-11T17:01:11.124424Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = pd.read_pickle('../data/trend_data/backup_tsdb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T17:01:13.027821Z",
     "start_time": "2020-08-11T17:01:12.996768Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                 cwe         ee  hwe  hws_flow     hws_rt  \\\n2019-10-28 14:20:00+00:00   9.521168   0.000000  0.0       0.0  85.925285   \n2019-10-28 14:25:00+00:00  10.351527  54.427879  0.0       0.0  86.224403   \n2019-10-28 14:30:00+00:00   9.135771   0.000000  0.0       0.0  86.224403   \n2019-10-28 14:35:00+00:00   7.425380   0.000000  0.0       0.0  86.569580   \n2019-10-28 14:40:00+00:00   5.760815  46.538872  0.0       0.0  86.569580   \n2019-10-28 14:45:00+00:00   3.469514   0.000000  0.0       0.0  86.569580   \n2019-10-28 14:50:00+00:00   0.034198   0.000000  0.0       0.0  86.569580   \n2019-10-28 14:55:00+00:00   0.034268   0.000000  0.0       0.0  86.891685   \n2019-10-28 15:00:00+00:00   2.217752   0.000000  0.0       0.0  86.891685   \n\n                               hws_st  hws_st_stpt  hws_vlv1        oah  \\\n2019-10-28 14:20:00+00:00  118.815613   106.990814       0.0  65.516228   \n2019-10-28 14:25:00+00:00  118.507637   106.990814       0.0  65.249855   \n2019-10-28 14:30:00+00:00  118.507637   106.990814       0.0  65.249855   \n2019-10-28 14:35:00+00:00  118.205322   106.990814       0.0  64.310364   \n2019-10-28 14:40:00+00:00  117.902885   106.990814       0.0  64.310364   \n2019-10-28 14:45:00+00:00  117.584175   106.990814       0.0  63.946850   \n2019-10-28 14:50:00+00:00  117.584175   106.586853       0.0  63.946850   \n2019-10-28 14:55:00+00:00  117.277527   106.193031       0.0  63.262836   \n2019-10-28 15:00:00+00:00  117.277527   105.800461       0.0  63.262836   \n\n                                 oat  ...  vrf34  vrf40  vrf50  vrf60  vrf63  \\\n2019-10-28 14:20:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:25:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:30:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:35:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:40:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:45:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:50:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 14:55:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n2019-10-28 15:00:00+00:00  55.813305  ...   70.0   70.0   70.0   70.0   78.0   \n\n                           vrf64  vrf67  vrf74  vrf77        wbt  \n2019-10-28 14:20:00+00:00   70.0   71.0   70.0   77.0  49.740982  \n2019-10-28 14:25:00+00:00   70.0   71.0   70.0   77.0  49.691269  \n2019-10-28 14:30:00+00:00   70.0   71.0   70.0   77.0  49.691269  \n2019-10-28 14:35:00+00:00   70.0   71.0   70.0   77.0  49.515565  \n2019-10-28 14:40:00+00:00   70.0   71.0   70.0   77.0  49.515565  \n2019-10-28 14:45:00+00:00   70.0   71.0   70.0   77.0  49.447428  \n2019-10-28 14:50:00+00:00   70.0   71.0   70.0   77.0  49.447428  \n2019-10-28 14:55:00+00:00   70.0   71.0   70.0   77.0  49.318983  \n2019-10-28 15:00:00+00:00   70.0   71.0   70.0   77.0  49.318983  \n\n[9 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cwe</th>\n      <th>ee</th>\n      <th>hwe</th>\n      <th>hws_flow</th>\n      <th>hws_rt</th>\n      <th>hws_st</th>\n      <th>hws_st_stpt</th>\n      <th>hws_vlv1</th>\n      <th>oah</th>\n      <th>oat</th>\n      <th>...</th>\n      <th>vrf34</th>\n      <th>vrf40</th>\n      <th>vrf50</th>\n      <th>vrf60</th>\n      <th>vrf63</th>\n      <th>vrf64</th>\n      <th>vrf67</th>\n      <th>vrf74</th>\n      <th>vrf77</th>\n      <th>wbt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-10-28 14:20:00+00:00</th>\n      <td>9.521168</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>85.925285</td>\n      <td>118.815613</td>\n      <td>106.990814</td>\n      <td>0.0</td>\n      <td>65.516228</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.740982</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:25:00+00:00</th>\n      <td>10.351527</td>\n      <td>54.427879</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.224403</td>\n      <td>118.507637</td>\n      <td>106.990814</td>\n      <td>0.0</td>\n      <td>65.249855</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.691269</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:30:00+00:00</th>\n      <td>9.135771</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.224403</td>\n      <td>118.507637</td>\n      <td>106.990814</td>\n      <td>0.0</td>\n      <td>65.249855</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.691269</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:35:00+00:00</th>\n      <td>7.425380</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.569580</td>\n      <td>118.205322</td>\n      <td>106.990814</td>\n      <td>0.0</td>\n      <td>64.310364</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.515565</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:40:00+00:00</th>\n      <td>5.760815</td>\n      <td>46.538872</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.569580</td>\n      <td>117.902885</td>\n      <td>106.990814</td>\n      <td>0.0</td>\n      <td>64.310364</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.515565</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:45:00+00:00</th>\n      <td>3.469514</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.569580</td>\n      <td>117.584175</td>\n      <td>106.990814</td>\n      <td>0.0</td>\n      <td>63.946850</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.447428</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:50:00+00:00</th>\n      <td>0.034198</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.569580</td>\n      <td>117.584175</td>\n      <td>106.586853</td>\n      <td>0.0</td>\n      <td>63.946850</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.447428</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 14:55:00+00:00</th>\n      <td>0.034268</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.891685</td>\n      <td>117.277527</td>\n      <td>106.193031</td>\n      <td>0.0</td>\n      <td>63.262836</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.318983</td>\n    </tr>\n    <tr>\n      <th>2019-10-28 15:00:00+00:00</th>\n      <td>2.217752</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>86.891685</td>\n      <td>117.277527</td>\n      <td>105.800461</td>\n      <td>0.0</td>\n      <td>63.262836</td>\n      <td>55.813305</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>70.0</td>\n      <td>77.0</td>\n      <td>49.318983</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_.empty) | (df_.isnull().any().any()) | (df_.shape[0]<6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data from the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T19:12:48.049676Z",
     "start_time": "2020-08-08T19:12:46.986579Z"
    }
   },
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# import modules\n",
    "from alumni_scripts import data_process as dp\n",
    "from alumni_scripts import alumni_data_utils as utils\n",
    "import json\n",
    "import pandas as pd\n",
    "from influxdb import DataFrameClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T19:13:25.287834Z",
     "start_time": "2020-08-08T19:13:23.917315Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before the next steps launch influxd client at a cli\n",
    "sudo influxd\n",
    "\"\"\"\n",
    "# launch python client for influxdb\n",
    "client = DataFrameClient(host='localhost', port=8086)\n",
    "# switch to the databaase you want\n",
    "client.switch_database('bdx_batch_db')\n",
    "results_obj = client.query(\n",
    "    \"select * from alumni_data_v2\\\n",
    "    where time >= '2018-08-07 00:00:00' \\\n",
    "    and time < '2019-02-07 00:00:00'\" \n",
    ")\n",
    "df2 = results_obj['alumni_data_v2']\n",
    "df2.drop(columns=['aggregated','data_cleaned','time-interval'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create meta_data : Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T16:09:33.573019Z",
     "start_time": "2020-06-21T16:09:33.260632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# import modules\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create column_aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data/alumni_data_jul2dec2018.csv', index_col='time')\n",
    "\n",
    "d1 = {'column_names': list(df.columns)}\n",
    "column_aliases = [\n",
    "    'pchwst', 'vrf50', 'oat', 'sat', 'sat_stpt', 'oah', 'vrf67', 'pchw_flow',\n",
    "    'hwe', 'vrf1', 'vrf30', 'vrf34', 'vrf74', 'cwe', 'hws_st_stpt', 'vrf60',\n",
    "    'vrf63', 'hws_st', 'hws_vlv1', 'vrf77', 'vrf64', 'vrf10', 'ee', 'hws_rt',\n",
    "    'vrf100', 'vrf40', 'hws_flow', 'vrf108', 'vrf20'\n",
    "]\n",
    "\n",
    "d2 = {}\n",
    "for i, j in zip(df.columns, column_aliases):\n",
    "    d2.update({j:i})\n",
    "d1['column_aliases'] = d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create column stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stats = {}\n",
    "d3 = dict(df.describe())\n",
    "for key in d3.keys():\n",
    "    stats[key] = dict(d3[key])\n",
    "d1['column_stats'] = stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dump meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('../alumni_scripts/meta_data.json', 'w') as fp:\n",
    "    json.dump(d1, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Read meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../alumni_scripts/meta_data.json', 'r') as fp:\n",
    "        meta_data_ = json.load(fp)\n",
    "meta_data = meta_data_.copy()\n",
    "for key, value in meta_data_['column_stats'].items():\n",
    "    if value['std'] == 0:\n",
    "        meta_data['column_stats'][key]['std'] = 0.0001  # add small std for constant values\n",
    "stats = pd.DataFrame(meta_data['column_stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot data before and after cleaning: Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:24:58.464354Z",
     "start_time": "2020-06-27T21:24:58.457319Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# import modules\n",
    "from alumni_scripts import data_process as dp\n",
    "from alumni_scripts import alumni_data_utils as a_utils\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict\n",
    "from CoolProp.HumidAirProp import HAPropsSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:25:00.973908Z",
     "start_time": "2020-06-27T21:25:00.213527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# collate batch of data\n",
    "file_names = ['jul2dec2018', 'jan2jun2019', 'jul2dec2019', 'jan2jun2020']\n",
    "dflist = []\n",
    "for fname in file_names:\n",
    "    df_ = pd.read_csv('../data/raw_data/alumni_data_{}.csv'.format(fname))\n",
    "    df_['time'] = pd.to_datetime(df_['time'])\n",
    "    df_.set_index(keys='time',inplace=True, drop = True)\n",
    "    dflist.append(df_)\n",
    "df = a_utils.mergerows(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:25:07.126472Z",
     "start_time": "2020-06-27T21:25:07.115986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rh = df['WeatherDataProfile humidity']/100\n",
    "rh = rh.to_numpy()\n",
    "t_db = 5*(df['AHU_1 outdoorAirTemp']-32)/9 + 273.15\n",
    "t_db = t_db.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:41:31.154129Z",
     "start_time": "2020-06-27T21:25:12.798214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T = HAPropsSI('T_wb','R',rh,'T',t_db,'P',101325)\n",
    "t_f = 9*(T-273.15)/5 + 32\n",
    "df['wbt'] = t_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:41:39.084300Z",
     "start_time": "2020-06-27T21:41:39.078568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_aliases = [\n",
    "    'pchwst', 'vrf50', 'oat', 'sat', 'sat_stpt', 'oah', 'vrf67', 'pchw_flow',\n",
    "    'hwe', 'vrf1', 'vrf30', 'vrf34', 'vrf74', 'cwe', 'hws_st_stpt', 'vrf60',\n",
    "    'vrf63', 'hws_st', 'hws_vlv1', 'vrf77', 'vrf64', 'vrf10', 'ee', 'hws_rt',\n",
    "    'vrf100', 'vrf40', 'hws_flow', 'vrf108', 'vrf20', 'wbt'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:42:02.128280Z",
     "start_time": "2020-06-27T21:42:02.123146Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns = column_aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T21:45:00.901390Z",
     "start_time": "2020-06-27T21:45:00.708715Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../alumni_scripts/meta_data.json', 'r') as fp:\n",
    "        meta_data_ = json.load(fp)\n",
    "df_cleaned1 = dp.offline_batch_data_clean(meta_data_=meta_data_, df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T22:07:24.569559Z",
     "start_time": "2020-06-27T22:07:24.337523Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = {}\n",
    "d2 = dict(df_cleaned1.describe())\n",
    "for key in d2.keys():\n",
    "    stats[key] = dict(d2[key])\n",
    "d1 ={'column_stats' : stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T22:07:28.273294Z",
     "start_time": "2020-06-27T22:07:27.996903Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d3 = {'column_agg_type':\n",
    "    {\"pchwst\": \"mean\",\"vrf50\": \"mean\",\"oat\": \"mean\",\"sat\": \"mean\",\"sat_stpt\": \"mean\",\"oah\": \"mean\",\n",
    "    \"vrf67\": \"mean\",\"pchw_flow\": \"sum\",\"hwe\": \"sum\",\"vrf1\": \"mean\",\"vrf30\": \"mean\",\"vrf34\": \"mean\",\n",
    "    \"vrf74\": \"mean\",\"cwe\": \"sum\",\"hws_st_stpt\": \"mean\",\"vrf60\": \"mean\",\"vrf63\": \"mean\",\"hws_st\": \"mean\",\n",
    "    \"hws_vlv1\": \"sum\",\"vrf77\": \"mean\", \"vrf64\": \"mean\",\"vrf10\": \"mean\",\"ee\": \"sum\",\"hws_rt\": \"mean\",\n",
    "    \"vrf100\": \"mean\",\"vrf40\": \"mean\",\"hws_flow\": \"sum\",\"vrf108\": \"mean\",\"vrf20\": \"mean\", 'wbt' : \"mean\"\n",
    "}}\n",
    "\n",
    "# aggregate data\n",
    "rolling_sum_target, rolling_mean_target = [], []\n",
    "for key, value in d3['column_agg_type'].items():\n",
    "    if value == 'sum': rolling_sum_target.append(key)\n",
    "    else: rolling_mean_target.append(key)\n",
    "\n",
    "df_agg = df_cleaned1.copy()\n",
    "        \n",
    "df_agg[rolling_sum_target] =  a_utils.window_sum(df_agg, window_size=6, column_names=rolling_sum_target)\n",
    "df_agg[rolling_mean_target] =  a_utils.window_mean(df_agg, window_size=6, column_names=rolling_mean_target)\n",
    "df_agg = a_utils.dropNaNrows(df_agg)\n",
    "# sample at half hour\n",
    "df_agg = a_utils.sample_timeseries_df(df_agg, period=6)\n",
    "\n",
    "# Create column stats for half hour data\n",
    "stats_halfhour = {}\n",
    "d4 = OrderedDict(df_agg.describe())\n",
    "for key, alias in zip(d4.keys(),column_aliases):\n",
    "    stats_halfhour[alias] = dict(d4[key])\n",
    "d1['column_stats_half_hour'] = stats_halfhour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T22:07:59.003757Z",
     "start_time": "2020-06-27T22:07:58.994792Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../alumni_scripts/meta_data1.json', 'w') as fp:\n",
    "    json.dump(d1, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col_name in df.columns:\n",
    "    utils.dataframeplot(df[[col_name]],lazy=False,legend=True)\n",
    "    utils.dataframeplot(df_cleaned[[col_name]],lazy=False,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "scrolled": false
   },
   "source": [
    "## Create Time Series Data Base: Demo only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:24:14.854873Z",
     "start_time": "2020-06-19T20:24:13.316916Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# import modules\n",
    "from alumni_scripts import data_process as dp\n",
    "from alumni_scripts import alumni_data_utils as utils\n",
    "import json\n",
    "import pandas as pd\n",
    "from influxdb import DataFrameClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data/alumni_data_jul2dec2018.csv',)\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.set_index(keys='time',inplace=True, drop = True)\n",
    "df_cleaned = dp.offline_batch_data_clean(meta_data_path='../alumni_scripts/meta_data.json', df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before the next steps launch influxd client at a cli\n",
    "sudo influxd\n",
    "\"\"\"\n",
    "# launch python client for influxdb\n",
    "client = DataFrameClient(host='localhost', port=8086)\n",
    "# create a database inc case it's not there\n",
    "client.create_database('demo_alumni')\n",
    "# get list of database\n",
    "client.get_list_database()\n",
    "# switch to the databaase you want\n",
    "client.switch_database('demo_alumni')\n",
    "# write \"dataframe\" as \"measurements\"\n",
    "client.write_points(dataframe=df_cleaned, measurement='alumni_jul2dec2018', protocol='line', batch_size=5000)\n",
    "# see measurement added to curent db\n",
    "client.get_list_measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_obj = client.query(\n",
    "    \"select * from alumni_jul2dec2018 where time >= '2018-11-15 12:00:00' and time < '2018-11-15 12:05:00'\"\n",
    ")\n",
    "df2 = results_obj['alumni_jul2dec2018']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "results_obj2 = client.query(\n",
    "    \"select * from alumni_jul2dec2018 where time = '2018-11-15 12:00:00'\"\n",
    ")\n",
    "df3 = results_obj2['alumni_jul2dec2018']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop the database after the demo\n",
    "client.drop_database('demo_alumni')\n",
    "client.get_list_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# close client\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Code cemetery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T22:22:24.658879Z",
     "start_time": "2020-06-20T22:22:24.649558Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_str = '2018-11-15 13:12:00'\n",
    "from datetime import datetime, timedelta\n",
    "time_now = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')\n",
    "print(time_now)\n",
    "time_now_str = str(time_now)\n",
    "print(time_now_str)\n",
    "time_now ==time_now_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T16:17:03.354684Z",
     "start_time": "2020-06-21T16:17:03.349072Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../alumni_scripts/meta_data.json', 'r') as fp:\n",
    "        meta_data_ = json.load(fp)\n",
    "meta_data_['column_agg_type']['pchwst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T18:09:27.277220Z",
     "start_time": "2020-06-20T18:09:27.271113Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "meta_data_['column_agg_type'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T18:15:04.955338Z",
     "start_time": "2020-06-20T18:15:04.949929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rolling_sum_target = []\n",
    "rolling_mean_target = []\n",
    "for key, value in meta_data_['column_agg_type'].items():\n",
    "    if value == 'sum': rolling_sum_target.append(key)\n",
    "    else: rolling_mean_target.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T18:16:14.744650Z",
     "start_time": "2020-06-20T18:16:14.738769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rolling_sum_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = {'c': '11', 'b' : ['1f3','a']}\n",
    "with open('../logs/cwe_test_info.txt', 'a') as ifile:\n",
    "        ifile.write(json.dumps(q)+'\\n',)      \n",
    "with open('../logs/cwe_test_info.txt') as f:\n",
    "    for line in f:\n",
    "        document = json.loads(line)\n",
    "        print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T21:46:44.327977Z",
     "start_time": "2020-07-31T21:46:44.323491Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from CoolProp.HumidAirProp import HAPropsSI\n",
    "from dateutil import tz\n",
    "\n",
    "df_ = pd.read_csv('../data/trend_data/alumni_data_train.csv', )\n",
    "df_['time'] = pd.to_datetime(df_['time'])\n",
    "to_zone = tz.tzlocal()\n",
    "df_['time'] = df_['time'].apply(lambda x: x.astimezone(to_zone)) # convert time to loca timezones\n",
    "df_.set_index(keys='time',inplace=True, drop = True)\n",
    "df_ = a_utils.dropNaNrows(df_)\n",
    "\n",
    "rh = df_['WeatherDataProfile humidity']/100\n",
    "rh = rh.to_numpy()\n",
    "t_db = 5*(df_['AHU_1 outdoorAirTemp']-32)/9 + 273.15\n",
    "t_db = t_db.to_numpy()\n",
    "\n",
    "tdb_rh = np.concatenate((t_db.reshape(-1,1), rh.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T21:51:53.372663Z",
     "start_time": "2020-07-31T21:51:53.365208Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import psutil\n",
    "chunks = [\n",
    "    (sub_arr[:, 0].flatten(), sub_arr[:, 1].flatten(), cpu_id)\n",
    "    for cpu_id, sub_arr in enumerate(np.array_split(tdb_rh, multiprocessing.cpu_count(), axis=0))]\n",
    "\n",
    "def unpacking_apply_along_axis(all_args):\n",
    "    t_db, rh, cpu_id = all_args\n",
    "    \n",
    "    proc = psutil.Process()\n",
    "    proc.cpu_affinity([cpu_id])\n",
    "    \n",
    "    T = HAPropsSI('T_wb','R',rh,'T',t_db,'P',101325)\n",
    "    return T\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "individual_results = pool.map(unpacking_apply_along_axis, chunks)\n",
    "# Freeing the workers:\n",
    "pool.close()\n",
    "pool.join()\n",
    "final_T = np.concatenate(individual_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T17:07:29.575413Z",
     "start_time": "2020-08-01T17:07:28.300253Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T17:31:08.908739Z",
     "start_time": "2020-08-01T17:31:08.859039Z"
    }
   },
   "outputs": [],
   "source": [
    "basepath='../tmp/cwe_data/cwe'\n",
    "labelnames = ['sat-oat', 'oah', 'wbt', 'pchw_flow', 'cwe']\n",
    "X_train = np.load(basepath+'_X_train.npy')\n",
    "y_train = np.load(basepath+'_y_train.npy')\n",
    "X_val = np.load(basepath+'_X_val.npy')\n",
    "y_val = np.load(basepath+'_y_val.npy')\n",
    "\n",
    "train = np.concatenate((X_train, y_train), axis=-1)[:,0,:]\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(train.shape[1]):\n",
    "    fig.add_trace(go.Scatter(y=train[:, i], mode='lines', name=labelnames[i]))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Different Variables',\n",
    "                  xaxis_title='Time Points',\n",
    "                  yaxis_title='Scaled Values',\n",
    "                  font = {'family':'Times New Roman', 'size': 15})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T17:31:34.622151Z",
     "start_time": "2020-08-01T17:31:34.573219Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "basepath='../tmp/hwe_data/hwe'\n",
    "labelnames = ['oat', 'oah', 'wbt', 'sat-oat', 'hwe']\n",
    "X_train = np.load(basepath+'_X_train.npy')\n",
    "y_train = np.load(basepath+'_y_train.npy')\n",
    "X_val = np.load(basepath+'_X_val.npy')\n",
    "y_val = np.load(basepath+'_y_val.npy')\n",
    "\n",
    "train = np.concatenate((X_train, y_train), axis=-1)[:,0,:]\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(train.shape[1]):\n",
    "    fig.add_trace(go.Scatter(y=train[:, i], mode='lines', name=labelnames[i]))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Different Variables',\n",
    "                  xaxis_title='Time Points',\n",
    "                  yaxis_title='Scaled Values',\n",
    "                  font = {'family':'Times New Roman', 'size': 15})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T17:31:56.393633Z",
     "start_time": "2020-08-01T17:31:56.195464Z"
    }
   },
   "outputs": [],
   "source": [
    "basepath='../tmp/vlv_data/vlv'\n",
    "labelnames = ['oat', 'oah', 'wbt', 'sat-oat', 'vlv_off', 'vlv_on']\n",
    "X_train = np.load(basepath+'_X_train.npy')\n",
    "y_train = np.load(basepath+'_y_train.npy')\n",
    "X_val = np.load(basepath+'_X_val.npy')\n",
    "y_val = np.load(basepath+'_y_val.npy')\n",
    "\n",
    "train = np.concatenate((X_train, y_train), axis=-1)[:,0,:]\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(train.shape[1]):\n",
    "    fig.add_trace(go.Scatter(y=train[:, i], mode='lines', name=labelnames[i]))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout(title='Different Variables',\n",
    "                  xaxis_title='Time Points',\n",
    "                  yaxis_title='Scaled Values',\n",
    "                  font = {'family':'Times New Roman', 'size': 15})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('sbvenv1': venv)",
   "language": "python",
   "name": "python36964bitsbvenv1venvf8f19bb32ed941ad82d727bac6ccbb65"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}